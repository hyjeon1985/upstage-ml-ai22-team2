{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ  ì„œìš¸ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ì˜ˆì¸¡ ëª¨ë¸\n",
    "\n",
    "## ëª¨ë¸ ê°œìš”\n",
    "- **ì•Œê³ ë¦¬ì¦˜**: RandomForest Regressor\n",
    "- **í”¼ì²˜ ìˆ˜**: 21ê°œ (ìˆ˜ì¹˜í˜• 15ê°œ + ë²”ì£¼í˜• 6ê°œ)\n",
    "- **Validation ë°©ì‹**: ì‹œê³„ì—´ ë¶„í•  (Time-based Split)\n",
    "\n",
    "## ì‹œê³„ì—´ Validation\n",
    "ë¶€ë™ì‚° ê°€ê²© ì˜ˆì¸¡ì€ **ë¯¸ë˜ ì‹œì ì˜ ê°€ê²©**ì„ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œ, ë”°ë¼ì„œ Validationë„ ì‹¤ì œ ì˜ˆì¸¡ ìƒí™©ê³¼ ë™ì¼í•˜ê²Œ **ê³¼ê±° â†’ ë¯¸ë˜** ìˆœì„œë¡œ ë¶„í• .\n",
    "\n",
    "```\n",
    "ì¼ë°˜ì ì¸ Random Splitì˜ ë¬¸ì œ:\n",
    "  Train/Validì— 2017~2023 ë°ì´í„°ê°€ ë¬´ì‘ìœ„ë¡œ ì„ì„\n",
    "  â†’ 2023ë…„ ë°ì´í„°ë¡œ í•™ìŠµí•˜ê³  2020ë…„ ë°ì´í„°ë¡œ ê²€ì¦í•˜ëŠ” ìƒí™© ë°œìƒ\n",
    "  â†’ Validation ì ìˆ˜ê°€ ì‹¤ì œ ì„±ëŠ¥ì„ ë°˜ì˜í•˜ì§€ ëª»í•¨\n",
    "\n",
    "ì‹œê³„ì—´ Split:\n",
    "  Train: 2017.01 ~ 2023.03 (ê³¼ê±° ë°ì´í„°ë¡œ í•™ìŠµ)\n",
    "  Valid: 2023.04 ~ 2023.06 (Test ì§ì „ ì‹œê¸°ë¡œ ê²€ì¦)\n",
    "  Test:  2023.07 ~ 2023.09 (ì‹¤ì œ ì˜ˆì¸¡ ëŒ€ìƒ)\n",
    "  â†’ Validationì´ ì‹¤ì œ Test ìƒí™©ì„ ëª¨ì‚¬í•¨\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.spatial import cKDTree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from lab_core.util.path import raw_data_dir, ext_data_dir, out_dir\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1118822, 52)\n",
      "Test: (9272, 51)\n",
      "ì§€í•˜ì² ì—­: 768ê°œ\n",
      "ë²„ìŠ¤ì •ë¥˜ì¥: 12,584ê°œ\n",
      "ì¢Œí‘œ ë°ì´í„°: 8,477ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "train_path = raw_data_dir('train.csv')\n",
    "test_path = raw_data_dir('test.csv')\n",
    "subway_path = raw_data_dir('subway_feature.csv')\n",
    "bus_path = raw_data_dir('bus_feature.csv')\n",
    "coord_path = ext_data_dir('coord.csv')  # ì¹´ì¹´ì˜¤ APIë¡œ ìƒì„±í•œ ì¢Œí‘œ ë°ì´í„°\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "subway = pd.read_csv(subway_path)\n",
    "bus = pd.read_csv(bus_path)\n",
    "coord = pd.read_csv(coord_path)\n",
    "\n",
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")\n",
    "print(f\"ì§€í•˜ì² ì—­: {len(subway)}ê°œ\")\n",
    "print(f\"ë²„ìŠ¤ì •ë¥˜ì¥: {len(bus):,}ê°œ\")\n",
    "print(f\"ì¢Œí‘œ ë°ì´í„°: {len(coord):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train ê¸°ê°„]\n",
      "  ê³„ì•½ë…„ì›”: 200701 ~ 202306\n",
      "\n",
      "[Test ê¸°ê°„]\n",
      "  ê³„ì•½ë…„ì›”: 202307 ~ 202309\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ê¸°ê°„ í™•ì¸\n",
    "print(\"[Train ê¸°ê°„]\")\n",
    "print(f\"  ê³„ì•½ë…„ì›”: {train['ê³„ì•½ë…„ì›”'].min()} ~ {train['ê³„ì•½ë…„ì›”'].max()}\")\n",
    "\n",
    "print(\"\\n[Test ê¸°ê°„]\")\n",
    "print(f\"  ê³„ì•½ë…„ì›”: {test['ê³„ì•½ë…„ì›”'].min()} ~ {test['ê³„ì•½ë…„ì›”'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"ìœ„ê²½ë„ ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚° (km)\n",
    "    \n",
    "    Haversine ê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ì§€ì  ê°„ì˜ ëŒ€ì›ê±°ë¦¬(great-circle distance)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    ì§€êµ¬ë¥¼ ì™„ì „í•œ êµ¬ë¡œ ê°€ì •í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Parameters:\n",
    "        lat1, lon1: ì²« ë²ˆì§¸ ì§€ì ì˜ ìœ„ë„, ê²½ë„\n",
    "        lat2, lon2: ë‘ ë²ˆì§¸ ì§€ì ì˜ ìœ„ë„, ê²½ë„\n",
    "    \n",
    "    Returns:\n",
    "        ë‘ ì§€ì  ê°„ì˜ ê±°ë¦¬ (km)\n",
    "    \"\"\"\n",
    "    R = 6371  # ì§€êµ¬ ë°˜ì§€ë¦„ (km)\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_coords(train_df, test_df, coord_df):\n",
    "    \"\"\"ì¢Œí‘œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (coord.csv í™œìš©)\n",
    "    \n",
    "    ì¹´ì¹´ì˜¤ APIë¡œ ë¯¸ë¦¬ ìˆ˜ì§‘í•œ ì¢Œí‘œ ë°ì´í„°(coord.csv)ë¥¼ ì‚¬ìš©í•˜ì—¬\n",
    "    Train/Testì˜ ì¢Œí‘œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ì›ë‹ˆë‹¤.\n",
    "    \n",
    "    ë§¤í•‘ í‚¤: 'êµ¬ + ë„ë¡œëª…' (ì˜ˆ: 'ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123')\n",
    "    \n",
    "    Parameters:\n",
    "        train_df: í•™ìŠµ ë°ì´í„°í”„ë ˆì„\n",
    "        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„\n",
    "        coord_df: ì¢Œí‘œ ë°ì´í„°í”„ë ˆì„ (ë§¤í•‘í‚¤, ì¢Œí‘œX, ì¢Œí‘œY ì»¬ëŸ¼ í•„ìš”)\n",
    "    \n",
    "    Returns:\n",
    "        ì¢Œí‘œê°€ ì±„ì›Œì§„ (train, test) íŠœí”Œ\n",
    "    \"\"\"\n",
    "    train = train_df.copy()\n",
    "    test = test_df.copy()\n",
    "    \n",
    "    # ë§¤í•‘ í‚¤ ìƒì„± (êµ¬ + ë„ë¡œëª…)\n",
    "    train['êµ¬'] = train['ì‹œêµ°êµ¬'].str.split().str[1]\n",
    "    test['êµ¬'] = test['ì‹œêµ°êµ¬'].str.split().str[1]\n",
    "    train['ë§¤í•‘í‚¤'] = train['êµ¬'] + ' ' + train['ë„ë¡œëª…'].fillna('')\n",
    "    test['ë§¤í•‘í‚¤'] = test['êµ¬'] + ' ' + test['ë„ë¡œëª…'].fillna('')\n",
    "    \n",
    "    # ì¢Œí‘œ ë”•ì…”ë„ˆë¦¬ ìƒì„± (NaN ì œì™¸)\n",
    "    coord_valid = coord_df[coord_df['ì¢Œí‘œX'].notna()]\n",
    "    coord_dict = dict(zip(coord_valid['ë§¤í•‘í‚¤'], zip(coord_valid['ì¢Œí‘œX'], coord_valid['ì¢Œí‘œY'])))\n",
    "    print(f\"ì¢Œí‘œ ë”•ì…”ë„ˆë¦¬ í¬ê¸°: {len(coord_dict):,}ê°œ\")\n",
    "    \n",
    "    # Train ì¢Œí‘œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "    train_before = train['ì¢Œí‘œX'].isna().sum()\n",
    "    mask = train['ì¢Œí‘œX'].isna()\n",
    "    train.loc[mask, 'ì¢Œí‘œX'] = train.loc[mask, 'ë§¤í•‘í‚¤'].map(lambda x: coord_dict.get(x, (np.nan, np.nan))[0])\n",
    "    train.loc[mask, 'ì¢Œí‘œY'] = train.loc[mask, 'ë§¤í•‘í‚¤'].map(lambda x: coord_dict.get(x, (np.nan, np.nan))[1])\n",
    "    train_after = train['ì¢Œí‘œX'].isna().sum()\n",
    "    \n",
    "    # Test ì¢Œí‘œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "    test_before = test['ì¢Œí‘œX'].isna().sum()\n",
    "    mask = test['ì¢Œí‘œX'].isna()\n",
    "    test.loc[mask, 'ì¢Œí‘œX'] = test.loc[mask, 'ë§¤í•‘í‚¤'].map(lambda x: coord_dict.get(x, (np.nan, np.nan))[0])\n",
    "    test.loc[mask, 'ì¢Œí‘œY'] = test.loc[mask, 'ë§¤í•‘í‚¤'].map(lambda x: coord_dict.get(x, (np.nan, np.nan))[1])\n",
    "    test_after = test['ì¢Œí‘œX'].isna().sum()\n",
    "    \n",
    "    # ì„ì‹œ ì»¬ëŸ¼ ì œê±°\n",
    "    train = train.drop(columns=['ë§¤í•‘í‚¤'], errors='ignore')\n",
    "    test = test.drop(columns=['ë§¤í•‘í‚¤'], errors='ignore')\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\n[ì¢Œí‘œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ê²°ê³¼]\")\n",
    "    print(f\"  Train: {train_before:,} â†’ {train_after:,} (ì±„ì›€: {train_before - train_after:,})\")\n",
    "    print(f\"  Test: {test_before:,} â†’ {test_after:,} (ì±„ì›€: {test_before - test_after:,})\")\n",
    "    print(f\"\\n  Train ì»¤ë²„ìœ¨: {train['ì¢Œí‘œX'].notna().mean()*100:.1f}%\")\n",
    "    print(f\"  Test ì»¤ë²„ìœ¨: {test['ì¢Œí‘œX'].notna().mean()*100:.1f}%\")\n",
    "    \n",
    "\n",
    "    # ë‚¨ì€ ê²°ì¸¡ì¹˜ëŠ” êµ¬ í‰ê·  ì¢Œí‘œë¡œ ì±„ìš°ê¸°\n",
    "    combined = pd.concat([train, test], ignore_index=True)\n",
    "    gu_mean = combined[combined['ì¢Œí‘œX'].notna()].groupby('êµ¬')[['ì¢Œí‘œX', 'ì¢Œí‘œY']].mean().to_dict('index')\n",
    "    \n",
    "    for df in [train, test]:\n",
    "        mask = df['ì¢Œí‘œX'].isna()\n",
    "        for idx in df[mask].index:\n",
    "            gu = df.loc[idx, 'êµ¬']\n",
    "            if gu in gu_mean:\n",
    "                df.loc[idx, 'ì¢Œí‘œX'] = gu_mean[gu]['ì¢Œí‘œX']\n",
    "                df.loc[idx, 'ì¢Œí‘œY'] = gu_mean[gu]['ì¢Œí‘œY']\n",
    "\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_features(df):\n",
    "    \"\"\"ê¸°ë³¸ í”¼ì²˜ ìƒì„±\n",
    "    \n",
    "    ì›ë³¸ ë°ì´í„°ì—ì„œ íŒŒìƒë˜ëŠ” ê¸°ë³¸ í”¼ì²˜ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤:\n",
    "    - ì‹œêµ°êµ¬ì—ì„œ êµ¬, ë™ ì¶”ì¶œ\n",
    "    - ê³„ì•½ë…„ì›”ì—ì„œ ë…„, ì›”, ë¶„ê¸° ì¶”ì¶œ\n",
    "    - ê±´ë¬¼ ë‚˜ì´ ë° ì‹ ì¶• ì—¬ë¶€ ê³„ì‚°\n",
    "    - ê°•ë‚¨3êµ¬ ì—¬ë¶€ í”Œë˜ê·¸\n",
    "    - ë©´ì /ì¸µ êµ¬ê°„ ë²”ì£¼í™”\n",
    "    \n",
    "    Parameters:\n",
    "        df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„\n",
    "    \n",
    "    Returns:\n",
    "        í”¼ì²˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ì§€ì—­ ì •ë³´ íŒŒì‹± (êµ¬ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒì„±)\n",
    "    if 'êµ¬' not in df.columns:\n",
    "        df['êµ¬'] = df['ì‹œêµ°êµ¬'].str.split().str[1]\n",
    "    df['ë™'] = df['ì‹œêµ°êµ¬'].str.split().str[2]\n",
    "    \n",
    "    # ì‹œê°„ ê´€ë ¨ í”¼ì²˜\n",
    "    df['ê³„ì•½ë…„'] = df['ê³„ì•½ë…„ì›”'] // 100\n",
    "    df['ê³„ì•½ì›”'] = df['ê³„ì•½ë…„ì›”'] % 100\n",
    "    df['ê³„ì•½ë¶„ê¸°'] = (df['ê³„ì•½ì›”'] - 1) // 3 + 1\n",
    "    \n",
    "    # ê±´ë¬¼ ê´€ë ¨ í”¼ì²˜\n",
    "    df['ê±´ë¬¼ë‚˜ì´'] = df['ê³„ì•½ë…„'] - df['ê±´ì¶•ë…„ë„']\n",
    "    df['ì‹ ì¶•ì—¬ë¶€'] = (df['ê±´ë¬¼ë‚˜ì´'] <= 10).astype(int)  # 10ë…„ ì´í•˜ë©´ ì‹ ì¶•\n",
    "    \n",
    "    # ê°•ë‚¨ê¶Œ ì—¬ë¶€ (ë¶€ë™ì‚° í”„ë¦¬ë¯¸ì—„ ì§€ì—­)\n",
    "    ê°•ë‚¨3êµ¬ = ['ê°•ë‚¨êµ¬', 'ì„œì´ˆêµ¬', 'ì†¡íŒŒêµ¬']\n",
    "    df['ê°•ë‚¨ì—¬ë¶€'] = df['êµ¬'].isin(ê°•ë‚¨3êµ¬).astype(int)\n",
    "    \n",
    "    # ë©´ì  êµ¬ê°„ ë²”ì£¼í™”\n",
    "    bins = [0, 40, 60, 85, 135, float('inf')]\n",
    "    labels = ['ì´ˆì†Œí˜•', 'ì†Œí˜•', 'ì¤‘í˜•', 'ì¤‘ëŒ€í˜•', 'ëŒ€í˜•']\n",
    "    df['ë©´ì êµ¬ê°„'] = pd.cut(df['ì „ìš©ë©´ì (ã¡)'], bins=bins, labels=labels).astype(str)\n",
    "    \n",
    "    # ì¸µ êµ¬ê°„ ë²”ì£¼í™”\n",
    "    bins = [0, 5, 10, 20, float('inf')]\n",
    "    labels = ['ì €ì¸µ', 'ì¤‘ì €ì¸µ', 'ì¤‘ì¸µ', 'ê³ ì¸µ']\n",
    "    df['ì¸µêµ¬ê°„'] = pd.cut(df['ì¸µ'], bins=bins, labels=labels).astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transport_features(df, subway_df, bus_df):\n",
    "    \"\"\"êµí†µ ì ‘ê·¼ì„± í”¼ì²˜ ì¶”ê°€\n",
    "    \n",
    "    KDTreeë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ì•„íŒŒíŠ¸ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­/ë²„ìŠ¤ì •ë¥˜ì¥ê¹Œì§€ì˜\n",
    "    ê±°ë¦¬ì™€ ì¼ì • ë°˜ê²½ ë‚´ êµí†µì‹œì„¤ ê°œìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ìƒì„±ë˜ëŠ” í”¼ì²˜:\n",
    "    - ì§€í•˜ì² _ìµœê·¼ì ‘_ê±°ë¦¬: ê°€ì¥ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­ê¹Œì§€ ê±°ë¦¬ (km)\n",
    "    - ë²„ìŠ¤_ìµœê·¼ì ‘_ê±°ë¦¬: ê°€ì¥ ê°€ê¹Œìš´ ë²„ìŠ¤ì •ë¥˜ì¥ê¹Œì§€ ê±°ë¦¬ (km)\n",
    "    - ì§€í•˜ì² _500m_ê°œìˆ˜: ë°˜ê²½ 500m ë‚´ ì§€í•˜ì² ì—­ ìˆ˜\n",
    "    - ë²„ìŠ¤_300m_ê°œìˆ˜: ë°˜ê²½ 300m ë‚´ ë²„ìŠ¤ì •ë¥˜ì¥ ìˆ˜\n",
    "    \n",
    "    Parameters:\n",
    "        df: ì•„íŒŒíŠ¸ ë°ì´í„°í”„ë ˆì„ (ì¢Œí‘œX, ì¢Œí‘œY í•„ìš”)\n",
    "        subway_df: ì§€í•˜ì² ì—­ ë°ì´í„°í”„ë ˆì„\n",
    "        bus_df: ë²„ìŠ¤ì •ë¥˜ì¥ ë°ì´í„°í”„ë ˆì„\n",
    "    \n",
    "    Returns:\n",
    "        êµí†µ í”¼ì²˜ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # KDTree êµ¬ì¶• (ë¹ ë¥¸ ìµœê·¼ì ‘ ì´ì›ƒ íƒìƒ‰ì„ ìœ„í•´)\n",
    "    subway_coords = subway_df[['ìœ„ë„', 'ê²½ë„']].values\n",
    "    subway_tree = cKDTree(subway_coords)\n",
    "    bus_coords = bus_df[['Yì¢Œí‘œ', 'Xì¢Œí‘œ']].values\n",
    "    bus_tree = cKDTree(bus_coords)\n",
    "    apt_coords = df[['ì¢Œí‘œY', 'ì¢Œí‘œX']].values\n",
    "    \n",
    "    # ìµœê·¼ì ‘ êµí†µì‹œì„¤ ì°¾ê¸°\n",
    "    subway_dist, subway_idx = subway_tree.query(apt_coords, k=1)\n",
    "    bus_dist, bus_idx = bus_tree.query(apt_coords, k=1)\n",
    "    \n",
    "    # ì‹¤ì œ ê±°ë¦¬ ê³„ì‚° (Haversine ê³µì‹ ì‚¬ìš©)\n",
    "    df['ì§€í•˜ì² _ìµœê·¼ì ‘_ê±°ë¦¬'] = [\n",
    "        haversine_distance(apt_coords[i, 0], apt_coords[i, 1],\n",
    "            subway_coords[subway_idx[i], 0], subway_coords[subway_idx[i], 1])\n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "    df['ë²„ìŠ¤_ìµœê·¼ì ‘_ê±°ë¦¬'] = [\n",
    "        haversine_distance(apt_coords[i, 0], apt_coords[i, 1],\n",
    "            bus_coords[bus_idx[i], 0], bus_coords[bus_idx[i], 1])\n",
    "        for i in range(len(df))\n",
    "    ]\n",
    "    \n",
    "    # ë°˜ê²½ ë‚´ êµí†µì‹œì„¤ ê°œìˆ˜ (rì€ ì¢Œí‘œ ë‹¨ìœ„, ëŒ€ëµì ì¸ ê°’)\n",
    "    subway_500m = subway_tree.query_ball_point(apt_coords, r=0.005)  # ì•½ 500m\n",
    "    df['ì§€í•˜ì² _500m_ê°œìˆ˜'] = [len(x) for x in subway_500m]\n",
    "    bus_300m = bus_tree.query_ball_point(apt_coords, r=0.003)  # ì•½ 300m\n",
    "    df['ë²„ìŠ¤_300m_ê°œìˆ˜'] = [len(x) for x in bus_300m]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì „ì²˜ë¦¬ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1: ì¢Œí‘œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (coord.csv í™œìš©)\n",
      "============================================================\n",
      "ì¢Œí‘œ ë”•ì…”ë„ˆë¦¬ í¬ê¸°: 8,237ê°œ\n",
      "\n",
      "[ì¢Œí‘œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ê²°ê³¼]\n",
      "  Train: 869,670 â†’ 21,715 (ì±„ì›€: 847,955)\n",
      "  Test: 6,562 â†’ 17 (ì±„ì›€: 6,545)\n",
      "\n",
      "  Train ì»¤ë²„ìœ¨: 98.1%\n",
      "  Test ì»¤ë²„ìœ¨: 99.8%\n",
      "\n",
      "============================================================\n",
      "Step 2: ê¸°ë³¸ í”¼ì²˜ ìƒì„±\n",
      "============================================================\n",
      "ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "Step 3: êµí†µ í”¼ì²˜ ìƒì„±\n",
      "============================================================\n",
      "êµí†µ í”¼ì²˜ ìƒì„± ì™„ë£Œ\n",
      "CPU times: user 23.7 s, sys: 3.07 s, total: 26.7 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"=\"*60)\n",
    "print(\"Step 1: ì¢Œí‘œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (coord.csv í™œìš©)\")\n",
    "print(\"=\"*60)\n",
    "train, test = fill_missing_coords(train, test, coord)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 2: ê¸°ë³¸ í”¼ì²˜ ìƒì„±\")\n",
    "print(\"=\"*60)\n",
    "train = create_basic_features(train)\n",
    "test = create_basic_features(test)\n",
    "print(\"ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Step 3: êµí†µ í”¼ì²˜ ìƒì„±\")\n",
    "print(\"=\"*60)\n",
    "train = add_transport_features(train, subway, bus)\n",
    "test = add_transport_features(test, subway, bus)\n",
    "print(\"êµí†µ í”¼ì²˜ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. í”¼ì²˜ ì„ íƒ ë° ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ í”¼ì²˜ ìˆ˜: 21ê°œ\n",
      "  - ìˆ˜ì¹˜í˜•: 15ê°œ\n",
      "  - ë²”ì£¼í˜•: 6ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš©í•  í”¼ì²˜ ëª©ë¡ (ì´ 21ê°œ)\n",
    "feature_cols = [\n",
    "    # ìˆ˜ì¹˜í˜• í”¼ì²˜ (15ê°œ)\n",
    "    'ì „ìš©ë©´ì (ã¡)', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'ì¢Œí‘œX', 'ì¢Œí‘œY',\n",
    "    'ê³„ì•½ë…„', 'ê³„ì•½ì›”', 'ê±´ë¬¼ë‚˜ì´', 'ì‹ ì¶•ì—¬ë¶€', 'ê°•ë‚¨ì—¬ë¶€', 'ê³„ì•½ë¶„ê¸°',\n",
    "    'ì§€í•˜ì² _ìµœê·¼ì ‘_ê±°ë¦¬', 'ë²„ìŠ¤_ìµœê·¼ì ‘_ê±°ë¦¬', 'ì§€í•˜ì² _500m_ê°œìˆ˜', 'ë²„ìŠ¤_300m_ê°œìˆ˜',\n",
    "    # ë²”ì£¼í˜• í”¼ì²˜ (6ê°œ)\n",
    "    'êµ¬', 'ë™', 'ì•„íŒŒíŠ¸ëª…', 'ë„ë¡œëª…', 'ë©´ì êµ¬ê°„', 'ì¸µêµ¬ê°„'\n",
    "]\n",
    "\n",
    "categorical_cols = ['êµ¬', 'ë™', 'ì•„íŒŒíŠ¸ëª…', 'ë„ë¡œëª…', 'ë©´ì êµ¬ê°„', 'ì¸µêµ¬ê°„']\n",
    "\n",
    "print(f\"ì´ í”¼ì²˜ ìˆ˜: {len(feature_cols)}ê°œ\")\n",
    "print(f\"  - ìˆ˜ì¹˜í˜•: {len(feature_cols) - len(categorical_cols)}ê°œ\")\n",
    "print(f\"  - ë²”ì£¼í˜•: {len(categorical_cols)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  êµ¬: 25ê°œ í´ë˜ìŠ¤\n",
      "  ë™: 337ê°œ í´ë˜ìŠ¤\n",
      "  ì•„íŒŒíŠ¸ëª…: 6550ê°œ í´ë˜ìŠ¤\n",
      "  ë„ë¡œëª…: 9245ê°œ í´ë˜ìŠ¤\n",
      "  ë©´ì êµ¬ê°„: 5ê°œ í´ë˜ìŠ¤\n",
      "  ì¸µêµ¬ê°„: 5ê°œ í´ë˜ìŠ¤\n",
      "\n",
      "ì¸ì½”ë”© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë²”ì£¼í˜• í”¼ì²˜ Label Encoding\n",
    "# Trainê³¼ Testì— ëª¨ë‘ ë“±ì¥í•˜ëŠ” ê°’ë“¤ì„ í†µí•©í•˜ì—¬ ì¸ì½”ë”©\n",
    "encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = train[col].fillna('UNKNOWN').astype(str)\n",
    "    test[col] = test[col].fillna('UNKNOWN').astype(str)\n",
    "    # Train + Testì˜ ëª¨ë“  ê³ ìœ ê°’ìœ¼ë¡œ ì¸ì½”ë” í•™ìŠµ\n",
    "    all_values = list(set(train[col].unique()) | set(test[col].unique()))\n",
    "    le.fit(all_values)\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])\n",
    "    encoders[col] = le\n",
    "    print(f\"  {col}: {len(le.classes_)}ê°œ í´ë˜ìŠ¤\")\n",
    "\n",
    "print(\"\\nì¸ì½”ë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‹œê³„ì—´ ê¸°ë°˜ Train/Validation ë¶„í• \n",
    "\n",
    "ë¶€ë™ì‚° ê°€ê²© ì˜ˆì¸¡ì€ **ë¯¸ë˜ ì˜ˆì¸¡** ë¬¸ì œì´ë¯€ë¡œ, Validationë„ ì‹œê°„ ìˆœì„œë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **Train**: 2017.01 ~ 2023.03 (ê³¼ê±° ë°ì´í„°)\n",
    "- **Validation**: 2023.04 ~ 2023.06 (Test ì§ì „ ì‹œê¸°)\n",
    "- **Test**: 2023.07 ~ 2023.09 (ì‹¤ì œ ì˜ˆì¸¡ ëŒ€ìƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ì‹œê³„ì—´ Validation ë¶„í•  ê²°ê³¼\n",
      "============================================================\n",
      "Train: 1,108,190ê±´ (~ 2023.03)\n",
      "Valid: 10,632ê±´ (2023.04 ~ 2023.06)\n",
      "Test:  9,272ê±´ (2023.07 ~ 2023.09)\n",
      "\n",
      "[Train ê¸°ê°„] 200701 ~ 202303\n",
      "[Valid ê¸°ê°„] 202304 ~ 202306\n",
      "[Test ê¸°ê°„]  202307 ~ 202309\n"
     ]
    }
   ],
   "source": [
    "# ì‹œê³„ì—´ ê¸°ì¤€ ë¶„í• \n",
    "train_mask = train['ê³„ì•½ë…„ì›”'] <= 202303\n",
    "valid_mask = (train['ê³„ì•½ë…„ì›”'] >= 202304) & (train['ê³„ì•½ë…„ì›”'] <= 202306)\n",
    "\n",
    "X_train = train.loc[train_mask, feature_cols]\n",
    "y_train = train.loc[train_mask, 'target']\n",
    "\n",
    "X_val = train.loc[valid_mask, feature_cols]\n",
    "y_val = train.loc[valid_mask, 'target']\n",
    "\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ì‹œê³„ì—´ Validation ë¶„í•  ê²°ê³¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train: {X_train.shape[0]:,}ê±´ (~ 2023.03)\")\n",
    "print(f\"Valid: {X_val.shape[0]:,}ê±´ (2023.04 ~ 2023.06)\")\n",
    "print(f\"Test:  {X_test.shape[0]:,}ê±´ (2023.07 ~ 2023.09)\")\n",
    "\n",
    "# ê¸°ê°„ í™•ì¸\n",
    "print(f\"\\n[Train ê¸°ê°„] {train.loc[train_mask, 'ê³„ì•½ë…„ì›”'].min()} ~ {train.loc[train_mask, 'ê³„ì•½ë…„ì›”'].max()}\")\n",
    "print(f\"[Valid ê¸°ê°„] {train.loc[valid_mask, 'ê³„ì•½ë…„ì›”'].min()} ~ {train.loc[valid_mask, 'ê³„ì•½ë…„ì›”'].max()}\")\n",
    "print(f\"[Test ê¸°ê°„]  {test['ê³„ì•½ë…„ì›”'].min()} ~ {test['ê³„ì•½ë…„ì›”'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì‹œê³„ì—´ Validation ê²°ê³¼]\n",
      "Validation RMSE: 17,200\n",
      "\n",
      "â€» ì‹œê³„ì—´ ë¶„í• ì„ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ, ì´ RMSEê°€ ì‹¤ì œ ë¦¬ë”ë³´ë“œ ì ìˆ˜ì™€ ìœ ì‚¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\n",
      "CPU times: user 1h 12min 22s, sys: 7.59 s, total: 1h 12min 30s\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RandomForest ëª¨ë¸ í•™ìŠµ\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,      # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "    max_depth=20,          # ìµœëŒ€ ê¹Šì´\n",
    "    min_samples_split=5,   # ë¶„í• ì„ ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
    "    random_state=42,       # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ\n",
    "    n_jobs=-1              # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation ì„±ëŠ¥ í‰ê°€\n",
    "val_pred = model.predict(X_val)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "\n",
    "print(f\"\\n[ì‹œê³„ì—´ Validation ê²°ê³¼]\")\n",
    "print(f\"Validation RMSE: {val_rmse:,.0f}\")\n",
    "print(f\"\\nâ€» ì‹œê³„ì—´ ë¶„í• ì„ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ, ì´ RMSEê°€ ì‹¤ì œ ë¦¬ë”ë³´ë“œ ì ìˆ˜ì™€ ìœ ì‚¬í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[í”¼ì²˜ ì¤‘ìš”ë„ Top 15]\n",
      "   1. ì „ìš©ë©´ì (ã¡): 0.3883\n",
      "   2. ê³„ì•½ë…„: 0.1870\n",
      "   3. ê°•ë‚¨ì—¬ë¶€: 0.1359\n",
      "   4. ê±´ì¶•ë…„ë„: 0.0652\n",
      "   5. ì¢Œí‘œX: 0.0565\n",
      "   6. ì¢Œí‘œY: 0.0530\n",
      "   7. êµ¬: 0.0207\n",
      "   8. ê±´ë¬¼ë‚˜ì´: 0.0159\n",
      "   9. ë„ë¡œëª…: 0.0156\n",
      "  10. ì§€í•˜ì² _ìµœê·¼ì ‘_ê±°ë¦¬: 0.0107\n",
      "  11. ë²„ìŠ¤_300m_ê°œìˆ˜: 0.0092\n",
      "  12. ì•„íŒŒíŠ¸ëª…: 0.0089\n",
      "  13. ë²„ìŠ¤_ìµœê·¼ì ‘_ê±°ë¦¬: 0.0088\n",
      "  14. ë™: 0.0087\n",
      "  15. ì¸µ: 0.0059\n"
     ]
    }
   ],
   "source": [
    "# í”¼ì²˜ ì¤‘ìš”ë„ í™•ì¸\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"[í”¼ì²˜ ì¤‘ìš”ë„ Top 15]\")\n",
    "for i, (_, row) in enumerate(importance.head(15).iterrows()):\n",
    "    print(f\"  {i+1:2}. {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì „ì²´ Trainìœ¼ë¡œ ì¬í•™ìŠµ í›„ ì˜ˆì¸¡\n",
    "\n",
    "Validationìœ¼ë¡œ ì„±ëŠ¥ì„ í™•ì¸í•œ í›„, ìµœì¢… ì œì¶œì„ ìœ„í•´ ì „ì²´ Train ë°ì´í„°ë¡œ ë‹¤ì‹œ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ Train ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì¤‘...\n",
      "í•™ìŠµ ì™„ë£Œ: 1,118,822ê±´\n",
      "CPU times: user 1h 19min 44s, sys: 15.7 s, total: 1h 20min\n",
      "Wall time: 5min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ì œì¶œìš©: ì „ì²´ Train ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
    "print(\"ì „ì²´ Train ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì¤‘...\")\n",
    "\n",
    "X_full = train[feature_cols]\n",
    "y_full = train['target']\n",
    "\n",
    "model_final = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model_final.fit(X_full, y_full)\n",
    "print(f\"í•™ìŠµ ì™„ë£Œ: {X_full.shape[0]:,}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ê°’ ë²”ìœ„: 7,615 ~ 1,204,781\n",
      "ì˜ˆì¸¡ê°’ í‰ê· : 108,942\n"
     ]
    }
   ],
   "source": [
    "# Test ë°ì´í„° ì˜ˆì¸¡\n",
    "test_pred = model_final.predict(X_test)\n",
    "\n",
    "print(f\"ì˜ˆì¸¡ê°’ ë²”ìœ„: {test_pred.min():,.0f} ~ {test_pred.max():,.0f}\")\n",
    "print(f\"ì˜ˆì¸¡ê°’ í‰ê· : {test_pred.mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/home/hyjeo/Workspaces/upstage-ml-ai22-team2/outputs/wjk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m out_dir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwjk/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file_name)\n\u001b[1;32m      9\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: test_pred\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     11\u001b[0m })\n\u001b[0;32m---> 13\u001b[0m \u001b[43msubmission\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì œì¶œ íŒŒì¼ ì €ì¥: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(submission\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/Workspaces/upstage-ml-ai22-team2/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspaces/upstage-ml-ai22-team2/.venv/lib/python3.10/site-packages/pandas/core/generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3718\u001b[0m )\n\u001b[0;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspaces/upstage-ml-ai22-team2/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspaces/upstage-ml-ai22-team2/.venv/lib/python3.10/site-packages/pandas/io/formats/format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1188\u001b[0m )\n\u001b[0;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Workspaces/upstage-ml-ai22-team2/.venv/lib/python3.10/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Workspaces/upstage-ml-ai22-team2/.venv/lib/python3.10/site-packages/pandas/io/common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 734\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Workspaces/upstage-ml-ai22-team2/.venv/lib/python3.10/site-packages/pandas/io/common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    595\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/home/hyjeo/Workspaces/upstage-ml-ai22-team2/outputs/wjk'"
     ]
    }
   ],
   "source": [
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "date_time_str = now.strftime('%Y%m%d_%H%M%S')\n",
    "file_name = f'output_{date_time_str}.csv'\n",
    "file_path = out_dir(\"wjk/\" + file_name)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'target': test_pred.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv(file_path, index=False)\n",
    "print(f\"ì œì¶œ íŒŒì¼ ì €ì¥: {file_name}\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì°¸ê³ : Validation ë°©ì‹ì— ë”°ë¥¸ ì°¨ì´\n",
    "\n",
    "| ë°©ì‹ | Train ë°ì´í„° | Validation ë°ì´í„° | íŠ¹ì§• |\n",
    "|------|-------------|-------------------|------|\n",
    "| Random Split | 2017~2023 ë¬´ì‘ìœ„ ì„ì„ | 2017~2023 ë¬´ì‘ìœ„ ì„ì„ | ë¯¸ë˜ ë°ì´í„°ë¡œ ê³¼ê±°ë¥¼ í‰ê°€í•˜ëŠ” ê²½ìš° ë°œìƒ |\n",
    "| **ì‹œê³„ì—´ Split** | **~2023.03** | **2023.04~06** | **ì‹¤ì œ ì˜ˆì¸¡ ìƒí™©ê³¼ ë™ì¼í•œ êµ¬ì¡°** |\n",
    "\n",
    "## ì„±ëŠ¥ ê°œì„  ì•„ì´ë””ì–´\n",
    "\n",
    "ì´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ê°œì„ í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **í”¼ì²˜ ì¶”ê°€**: í•™êµ° ì •ë³´, ì£¼ë³€ ìƒê¶Œ, ê³µì› ì ‘ê·¼ì„± ë“±\n",
    "2. **ì•™ìƒë¸”**: LightGBM, XGBoost ë“± ë‹¤ë¥¸ ëª¨ë¸ê³¼ ê²°í•©\n",
    "3. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: Optuna ë“±ì„ í™œìš©í•œ ìµœì í™”\n",
    "4. **í”¼ì²˜ ì„ íƒ**: ì¤‘ìš”ë„ê°€ ë‚®ì€ í”¼ì²˜ ì œê±° ì‹¤í—˜"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
